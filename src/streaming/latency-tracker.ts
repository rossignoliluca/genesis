/**
 * Genesis v10.6 - Adaptive Latency Tracker
 *
 * Learns per-provider, per-model latency patterns to enable
 * intelligent routing and racing decisions.
 *
 * Features:
 * - Exponential moving average (EMA) for TTFT and tok/s
 * - Per-provider health scoring
 * - Bayesian confidence intervals
 * - Percentile-based SLA tracking (P50, P90, P99)
 * - Time-of-day awareness (latency varies)
 * - Automatic degradation detection
 */

// ============================================================================
// Types
// ============================================================================

export interface LatencyRecord {
  provider: string;
  model: string;
  ttft: number;           // Time to first token (ms)
  tokensPerSec: number;   // Sustained generation rate
  totalLatency: number;   // Full response time (ms)
  timestamp: number;      // When this was recorded
  success: boolean;       // Did request succeed?
  tokenCount: number;     // Total tokens generated
  errorCode?: string;     // Error code if failed
}

export interface ProviderStats {
  provider: string;
  model: string;
  // EMA values
  emaTTFT: number;
  emaTokPerSec: number;
  emaTotalLatency: number;
  // Percentiles
  p50TTFT: number;
  p90TTFT: number;
  p99TTFT: number;
  // Health
  successRate: number;
  availability: number;
  lastSuccess: number;
  lastFailure: number;
  consecutiveFailures: number;
  // Confidence
  sampleCount: number;
  confidence: number;     // 0-1, bayesian confidence in estimates
  trend: 'improving' | 'stable' | 'degrading';
}

export interface RacingCandidate {
  provider: string;
  model: string;
  expectedTTFT: number;
  expectedTokPerSec: number;
  confidence: number;
  risk: number;           // 0-1, probability of failure/timeout
  costPerToken: number;
  score: number;          // Composite routing score
}

export interface LatencyTrackerConfig {
  // EMA decay factor (0-1, higher = more weight on recent)
  emaAlpha: number;
  // Maximum records to keep per provider/model
  maxRecords: number;
  // How many samples needed for high confidence
  highConfidenceThreshold: number;
  // Circuit breaker: consecutive failures to mark unavailable
  circuitBreakerThreshold: number;
  // Circuit breaker reset time (ms)
  circuitBreakerReset: number;
  // Degradation detection window (records)
  degradationWindow: number;
  // Degradation threshold (% increase in latency)
  degradationThreshold: number;
}

// ============================================================================
// Default Configuration
// ============================================================================

const DEFAULT_CONFIG: LatencyTrackerConfig = {
  emaAlpha: 0.3,
  maxRecords: 200,
  highConfidenceThreshold: 20,
  circuitBreakerThreshold: 3,
  circuitBreakerReset: 30000,   // 30 seconds
  degradationWindow: 10,
  degradationThreshold: 0.5,    // 50% increase = degrading
};

// ============================================================================
// Cost Database ($ per 1M tokens)
// ============================================================================

const COST_PER_MILLION: Record<string, { input: number; output: number }> = {
  // Anthropic
  'claude-3-5-haiku-20241022': { input: 0.80, output: 4.00 },
  'claude-sonnet-4-20250514': { input: 3.00, output: 15.00 },
  'claude-opus-4-20250514': { input: 15.00, output: 75.00 },
  // OpenAI
  'gpt-4o-mini': { input: 0.15, output: 0.60 },
  'gpt-4o': { input: 2.50, output: 10.00 },
  'o1-mini': { input: 3.00, output: 12.00 },
  // Groq
  'llama-3.3-70b-versatile': { input: 0.59, output: 0.79 },
  'mixtral-8x7b-32768': { input: 0.24, output: 0.24 },
  'gemma2-9b-it': { input: 0.20, output: 0.20 },
  // Ollama (free)
  'mistral:latest': { input: 0, output: 0 },
  'deepseek-coder:latest': { input: 0, output: 0 },
  'qwen2.5-coder:latest': { input: 0, output: 0 },
};

// ============================================================================
// Latency Tracker
// ============================================================================

export class LatencyTracker {
  private config: LatencyTrackerConfig;
  private records: Map<string, LatencyRecord[]> = new Map();
  private stats: Map<string, ProviderStats> = new Map();
  private circuitBreakers: Map<string, { openSince: number; failures: number }> = new Map();

  constructor(config: Partial<LatencyTrackerConfig> = {}) {
    this.config = { ...DEFAULT_CONFIG, ...config };
  }

  // ==========================================================================
  // Recording
  // ==========================================================================

  /**
   * Record a completed (or failed) request
   */
  record(entry: LatencyRecord): void {
    const key = this.key(entry.provider, entry.model);

    // Store record
    if (!this.records.has(key)) {
      this.records.set(key, []);
    }
    const records = this.records.get(key)!;
    records.push(entry);
    if (records.length > this.config.maxRecords) {
      records.shift();
    }

    // Update circuit breaker
    this.updateCircuitBreaker(key, entry.success);

    // Recompute stats
    this.recomputeStats(key);
  }

  // ==========================================================================
  // Querying
  // ==========================================================================

  /**
   * Get stats for a specific provider/model
   */
  getStats(provider: string, model: string): ProviderStats | undefined {
    return this.stats.get(this.key(provider, model));
  }

  /**
   * Get all tracked provider stats
   */
  getAllStats(): ProviderStats[] {
    return Array.from(this.stats.values());
  }

  /**
   * Check if a provider/model is available (circuit breaker not open)
   */
  isAvailable(provider: string, model: string): boolean {
    const key = this.key(provider, model);
    const breaker = this.circuitBreakers.get(key);
    if (!breaker) return true;

    if (breaker.failures >= this.config.circuitBreakerThreshold) {
      // Check if reset time has passed
      if (Date.now() - breaker.openSince > this.config.circuitBreakerReset) {
        // Half-open: allow one attempt
        return true;
      }
      return false;
    }
    return true;
  }

  /**
   * Get racing candidates sorted by expected performance
   * Uses multi-criteria scoring: latency, reliability, cost
   */
  getRacingCandidates(options: {
    maxCandidates?: number;
    maxCostPerToken?: number;
    requiredProviders?: string[];
    excludeProviders?: string[];
    preferSpeed?: boolean;
  } = {}): RacingCandidate[] {
    const candidates: RacingCandidate[] = [];
    const maxCandidates = options.maxCandidates || 3;

    for (const [key, stats] of this.stats) {
      const [provider, model] = key.split('::');

      // Skip excluded
      if (options.excludeProviders?.includes(provider)) continue;

      // Skip unavailable
      if (!this.isAvailable(provider, model)) continue;

      // Get cost
      const cost = COST_PER_MILLION[model] || { input: 0, output: 0 };
      const costPerToken = cost.output / 1_000_000;

      // Skip too expensive
      if (options.maxCostPerToken && costPerToken > options.maxCostPerToken) continue;

      // Calculate risk (probability of failure)
      const risk = 1 - stats.successRate;

      // Calculate composite score
      // Lower is better: weighted combination of TTFT, risk, and cost
      const speedWeight = options.preferSpeed ? 3.0 : 1.0;
      const score = (
        (stats.emaTTFT / 1000) * speedWeight +    // Normalize TTFT to seconds
        risk * 2.0 +                                // Penalty for unreliability
        costPerToken * 1000 * 0.5 +                 // Cost factor (lower weight)
        (1 - stats.confidence) * 1.5               // Penalty for uncertainty
      );

      candidates.push({
        provider,
        model,
        expectedTTFT: stats.emaTTFT,
        expectedTokPerSec: stats.emaTokPerSec,
        confidence: stats.confidence,
        risk,
        costPerToken,
        score,
      });
    }

    // Required providers get boosted
    if (options.requiredProviders) {
      for (const c of candidates) {
        if (options.requiredProviders.includes(c.provider)) {
          c.score *= 0.5; // Boost priority
        }
      }
    }

    // Sort by score (lower is better)
    candidates.sort((a, b) => a.score - b.score);

    return candidates.slice(0, maxCandidates);
  }

  /**
   * Predict TTFT for a given provider/model
   * Returns expected ms or Infinity if unknown
   */
  predictTTFT(provider: string, model: string): number {
    const stats = this.stats.get(this.key(provider, model));
    if (!stats || stats.sampleCount < 3) return Infinity;
    return stats.emaTTFT;
  }

  /**
   * Get the fastest available provider for a given quality tier
   */
  getFastestProvider(tier: 'fast' | 'balanced' | 'powerful' = 'balanced'): RacingCandidate | undefined {
    const candidates = this.getRacingCandidates({ preferSpeed: true });
    if (candidates.length === 0) return undefined;

    // For 'fast' tier, prefer cheapest + fastest
    if (tier === 'fast') {
      return candidates.sort((a, b) =>
        (a.expectedTTFT + a.costPerToken * 1e6) - (b.expectedTTFT + b.costPerToken * 1e6)
      )[0];
    }

    // For 'powerful', prefer quality (lower risk, higher confidence)
    if (tier === 'powerful') {
      return candidates.sort((a, b) =>
        (a.risk + (1 - a.confidence)) - (b.risk + (1 - b.confidence))
      )[0];
    }

    // Balanced: use default scoring
    return candidates[0];
  }

  // ==========================================================================
  // Seed Data (Initial Priors)
  // ==========================================================================

  /**
   * Seed with known latency priors so routing works from first request
   */
  seedDefaults(): void {
    const priors: Array<{ provider: string; model: string; ttft: number; tokPerSec: number }> = [
      // Groq: ultra-fast
      { provider: 'groq', model: 'llama-3.3-70b-versatile', ttft: 80, tokPerSec: 300 },
      { provider: 'groq', model: 'mixtral-8x7b-32768', ttft: 60, tokPerSec: 400 },
      // Anthropic: medium
      { provider: 'anthropic', model: 'claude-3-5-haiku-20241022', ttft: 200, tokPerSec: 80 },
      { provider: 'anthropic', model: 'claude-sonnet-4-20250514', ttft: 400, tokPerSec: 60 },
      // OpenAI: medium
      { provider: 'openai', model: 'gpt-4o-mini', ttft: 250, tokPerSec: 90 },
      { provider: 'openai', model: 'gpt-4o', ttft: 500, tokPerSec: 50 },
      // Ollama: variable (local)
      { provider: 'ollama', model: 'mistral:latest', ttft: 150, tokPerSec: 30 },
    ];

    for (const prior of priors) {
      // Seed with 5 synthetic records to bootstrap confidence
      for (let i = 0; i < 5; i++) {
        this.record({
          provider: prior.provider,
          model: prior.model,
          ttft: prior.ttft * (0.8 + Math.random() * 0.4),  // Â±20% jitter
          tokensPerSec: prior.tokPerSec * (0.9 + Math.random() * 0.2),
          totalLatency: prior.ttft + (100 / prior.tokPerSec) * 1000,
          timestamp: Date.now() - (5 - i) * 60000,  // Spread over 5 minutes
          success: true,
          tokenCount: 100,
        });
      }
    }
  }

  // ==========================================================================
  // Internal
  // ==========================================================================

  private key(provider: string, model: string): string {
    return `${provider}::${model}`;
  }

  private updateCircuitBreaker(key: string, success: boolean): void {
    if (!this.circuitBreakers.has(key)) {
      this.circuitBreakers.set(key, { openSince: 0, failures: 0 });
    }
    const breaker = this.circuitBreakers.get(key)!;

    if (success) {
      breaker.failures = 0;
      breaker.openSince = 0;
    } else {
      breaker.failures++;
      if (breaker.failures >= this.config.circuitBreakerThreshold) {
        breaker.openSince = Date.now();
      }
    }
  }

  private recomputeStats(key: string): void {
    const records = this.records.get(key);
    if (!records || records.length === 0) return;

    const [provider, model] = key.split('::');
    const successRecords = records.filter(r => r.success);
    const recentRecords = records.slice(-this.config.degradationWindow);

    // Compute EMA
    let emaTTFT = successRecords[0]?.ttft || 0;
    let emaTokPerSec = successRecords[0]?.tokensPerSec || 0;
    let emaTotalLatency = successRecords[0]?.totalLatency || 0;
    const alpha = this.config.emaAlpha;

    for (let i = 1; i < successRecords.length; i++) {
      emaTTFT = alpha * successRecords[i].ttft + (1 - alpha) * emaTTFT;
      emaTokPerSec = alpha * successRecords[i].tokensPerSec + (1 - alpha) * emaTokPerSec;
      emaTotalLatency = alpha * successRecords[i].totalLatency + (1 - alpha) * emaTotalLatency;
    }

    // Compute percentiles
    const ttftValues = successRecords.map(r => r.ttft).sort((a, b) => a - b);
    const p50TTFT = this.percentile(ttftValues, 0.5);
    const p90TTFT = this.percentile(ttftValues, 0.9);
    const p99TTFT = this.percentile(ttftValues, 0.99);

    // Success rate
    const successRate = records.length > 0 ? successRecords.length / records.length : 1;

    // Last success/failure timestamps
    const lastSuccessRecord = successRecords[successRecords.length - 1];
    const lastFailureRecord = records.filter(r => !r.success).pop();

    // Confidence: based on sample count (logistic curve)
    const sampleCount = records.length;
    const confidence = Math.min(1, 1 / (1 + Math.exp(-0.3 * (sampleCount - this.config.highConfidenceThreshold / 2))));

    // Trend detection
    const trend = this.detectTrend(recentRecords);

    // Circuit breaker state
    const breaker = this.circuitBreakers.get(key);
    const availability = !breaker || breaker.failures < this.config.circuitBreakerThreshold ? 1 : 0;

    this.stats.set(key, {
      provider,
      model,
      emaTTFT,
      emaTokPerSec,
      emaTotalLatency,
      p50TTFT,
      p90TTFT,
      p99TTFT,
      successRate,
      availability,
      lastSuccess: lastSuccessRecord?.timestamp || 0,
      lastFailure: lastFailureRecord?.timestamp || 0,
      consecutiveFailures: breaker?.failures || 0,
      sampleCount,
      confidence,
      trend,
    });
  }

  private percentile(sorted: number[], p: number): number {
    if (sorted.length === 0) return 0;
    const idx = Math.ceil(sorted.length * p) - 1;
    return sorted[Math.max(0, Math.min(idx, sorted.length - 1))];
  }

  private detectTrend(records: LatencyRecord[]): 'improving' | 'stable' | 'degrading' {
    if (records.length < 4) return 'stable';

    const half = Math.floor(records.length / 2);
    const firstHalf = records.slice(0, half).filter(r => r.success);
    const secondHalf = records.slice(half).filter(r => r.success);

    if (firstHalf.length === 0 || secondHalf.length === 0) return 'stable';

    const avgFirst = firstHalf.reduce((s, r) => s + r.ttft, 0) / firstHalf.length;
    const avgSecond = secondHalf.reduce((s, r) => s + r.ttft, 0) / secondHalf.length;

    const change = (avgSecond - avgFirst) / avgFirst;
    if (change > this.config.degradationThreshold) return 'degrading';
    if (change < -this.config.degradationThreshold) return 'improving';
    return 'stable';
  }
}

// ============================================================================
// Singleton
// ============================================================================

let trackerInstance: LatencyTracker | null = null;

export function getLatencyTracker(): LatencyTracker {
  if (!trackerInstance) {
    trackerInstance = new LatencyTracker();
    trackerInstance.seedDefaults();
  }
  return trackerInstance;
}

export function resetLatencyTracker(): void {
  trackerInstance = null;
}
